# Part 1 EDA in ML100-Days
機器學習百日馬拉松：
第一部分 EDA 共 16天


https://www.cupoy.com/home

未來 100天的學習是這樣計畫的，
從資料與觀察特徵開始，然後開始見模型或是建架 "機器學習實踐人工智慧" 的框架，花一天調教，四天到五天作一題 Kaggle 作驗收。
然後在前往深度學習之前，我們會經歷很實際的問題討論非監督式學習，最後三十多天會進入神玄的機器學習的課程。

首先的16天，我們是資料清理數據前處理。

在 Cupoy 的機器學習百日馬拉松的課程中，缺乏整理的介紹，直接進入了 100天的介紹，就算第一天有一些提醒與很棒的延伸教材，
但是對於一些沒有留意同學，可能有點見樹不見林，學了之後，可能未來有解題能力，但是拿到問題的霎那會不知道如何下手。

所以在出發前，我先把我要的過程說明，資料清理沒有一個標準程序，但是初學的同學，可以把這 16天的學習當作一個規範出發，慢慢在靈活發展。

我們收到了一個問題，這 16要好好地做好前處理，才會進行特徵挑選與整理，
	• Day 1: 各位小姐姐小哥哥，收到一個問題先不要急著跳進去，請好好的了解問題安排資源與規劃作法。
	• Day 2: 我們第一次進行 EDA，是從資料的筆數、欄位多寡開始認識我們手中有多少東西。當然不要忘了我們也閱讀的欄位的描述文件。
	• Day 4: 我們開始跳進去欄位去看所有欄位的資料格式，查看是浮點數、整數或物件資料。對於類別型資料我們馬上進行編碼工作。
	• Day 5: 我們學習繼續留在欄位中觀察他們的基本統計資料。
		我們可以這麼說，
		Day 4 用 app_train.dtypes.value_counts() 與 app_train.select_dtypes(include=["object"]).apply(pd.Series.nunique, axis = 0) 來了解各種資料型態的個數與找出所有類別型資料與檢視類別型欄位各自類別的數量。
		Day 5 是用 .describe() 看欄位資料的統計特徵與用 plt.hist() 去劃出直方圖 histogram 讓我們認識欄位資料。
	• Day 6: 在經過 Day 5 的統計資訊觀察後，我們在 Day 6就要初步判斷是否有 outlier 異常資料，這次有用到 boxplot 圖。
	• Day 7: 跟 Day 6 是連續動作，對於一些 outlier 的處理，同時當個別欄位資料的 outlier 都處理的，我們也不希望整體的欄位中有某幾個因為單位不依樣因為數值特別大讓我們後續模型運算時有不平衡的影響，所以就一併作了標準化。
	• Day 9, 10: 當我們基本資料觀察與修正了之後，我們就展開了所有特徵值(欄位資料)對於 目標 的相關運算。
	• Day 11: 觀察單一特徵值的統計甚至進入該特徵值觀看是否有子區的個別特徵，我們會介紹 KDE 與 pdf。這些微細的觀察都是讓我們對於觀察對象及其特徵更清楚的認識與掌握。
	• Day 12，13，14: 把連續型變數離散化，有些特徵值如果作了分群，比如年紀，分成<25，介於 25 ~ 45，與 > 45 可能會有不錯的效果。
	• Day 16: 差不多所有的資料的初步處理已經完成，所以進行整理後的特徵值的相關性，準備嘗試建立第一個機器學習的程式 (Day16)。


每一天進度的程式作業在
https://github.com/PatrickRuan/ML100-Days
可以幫忙按個 watch 或 follow ^^


Day 1: 當我們遇到一個問題時，不見得要馬上跳進去玩耍；
	
	我們要先思考問題，知道目的，如果有資料，還可以概略看一下資料，盤算能夠作出甚麼有趣有用的結果。
	如果沒有資料，就問題的思考後，才去採集資料，相對可以節省很多時間。
	
	之後我們才會盤算一個策略去進行行動，比如快速完成一個方案，一個最小可行方案(Minimum Visiable Product 的概念)，後續進行優化改善。
	
	HW: 除了第一天的簡易練習 編寫 Y=wX+b，plot(X,Y) 定義 mse, mae 還有一個很重要的工作，
	作業2：如果你今天經營一個台灣大車隊，你要如何透過數據分析來提升業績? 思考一下，我們除了需要工程師也需要資料分析師與科學家。
	程式作業，
	1.) 建立一個 y = w * x + b， w =3, b =5，x 具有 amplitude 5 的 Guassian Noice
	2.) def mae, and mse 2 functions
	3.) 學習 文字區編寫 $ MSE = \frac{1}{n}\sum_{i=1}^{n}{(Y_i - \hat{Y}_i)^2} $


Day 2: 第一次資料探勘

	好我們前十六天都將進行資料數據前處理的工作，練習的問題會是 Kaggle 上的題目 
	https://www.kaggle.com/c/home-credit-default-risk/data 
	
	會用到的應該是 application_train.csv 與 application_test.csv 
	最後要上傳時會用到 submission.csv 
	但是請不要忘了研讀 HomeCredit_columns_description.csv 
	
	HW:
	第二天我們開始讀取資料，對於這個被整理好的 Dataframe 進行最初步的探勘，比如說知道有多少筆資料，有多少 "欄" 的特徵，如何將特徵項目組成一個 list， 又或者我們該如何呈現截取部分資料等。總之，我們還沒有跳進去觀察個別特徵，個別資料前，我們所採取的動作在今天試著作一輪。
	第二天還有一個有趣的參考作業，讀一讀吳老師的資料探勘講義，其中為何要研究杜河的魚類又如何進行都是很有意義的練習，川普的故事也趣味十足。
	
	程式作業: 學會本程式的所有觀察，同時提出不懂的地方。
	
Day 3: 關於 DataFrame
	
	我們在作資料清理，在處理機器學習的問題時，常常都要熟練 DataFrame 的操作，DataFrame 就像是 EXCEL 的 Spreadsheet 一樣，第一列存著的是所有欄位名稱，就是我們未來要處理的特徵。第二列起就是一筆一筆的資料。
	
	HW: 第三天的練習會比 pandas 的 DataFrame 多一點不同格式的東西，大家好好努力!
	程式作業: 學會本日程式(有兩個)的所有觀察，同時提出不懂的地方。
